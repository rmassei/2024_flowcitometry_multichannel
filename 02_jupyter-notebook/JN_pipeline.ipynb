{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4578bdd9",
   "metadata": {},
   "source": "# JN pipeline"
  },
  {
   "cell_type": "markdown",
   "id": "bc8bdca9",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Jupyter Notebook to prepare flow cytofluometry data before input. The conversion will take the images extracted from the .cif file using the IFC package, convert to a multichannel image and add metadata to the .tif header.\n",
    "Furthermore, it is possible to import images into OMERO using ezomero and add the masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3837ef3",
   "metadata": {},
   "source": "####  Import python libraries"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac9504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import getpass\n",
    "\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import ezomero\n",
    "\n",
    "from omero.gateway import BlitzGateway\n",
    "from tifffile import TiffFile\n",
    "from skimage import filters\n",
    "from skimage.io import imread\n",
    "from ome_types import to_xml, OME\n",
    "from ome_types.model import Image, Pixels, Channel, TiffData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678717a",
   "metadata": {},
   "source": "####  Functions to create the multichannel tiff and associate mask into OMERO\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_channel_conversion(files_path, metadata_path, files_output):\n",
    "    with open(metadata_path, 'r') as file:\n",
    "        metadata = json.load(file)\n",
    "    channels = metadata['wavelenght']\n",
    "    channels = [item for sublist in channels for item in sublist]\n",
    "    print(channels)\n",
    "    os.chdir(files_path)\n",
    "    files = sorted(os.listdir(files_path), key=str.lower)\n",
    "    try:\n",
    "        len(files) % len(channels) != 0\n",
    "    except NameError:\n",
    "        print(f\"Something wrong with the file number, not multiples of {len(channels)}\")\n",
    "    else:\n",
    "        os.mkdir(files_output)\n",
    "        block_size = len(channels)\n",
    "        array_list = []\n",
    "        round = 0\n",
    "        for i in range(0, len(files), block_size):\n",
    "            block_files = files[i:i + block_size]\n",
    "            array_list.clear()\n",
    "            for im in block_files:\n",
    "                img = tifffile.imread(im)\n",
    "                array = np.rint((np.asarray(img) / 256) * 65535).astype(np.uint16)\n",
    "                array_list.append(array)\n",
    "                with TiffFile(f'{im}') as tif:\n",
    "                    sample = tif.pages[0]\n",
    "                    dtype = sample.dtype\n",
    "                    pixel = tif.pages[0].tags[\"SamplesPerPixel\"].value\n",
    "                    width = tif.pages[0].tags[\"ImageWidth\"].value\n",
    "                    lenght = tif.pages[0].tags[\"ImageLength\"].value\n",
    "                    bits = tif.pages[0].tags[\"BitsPerSample\"].value\n",
    "            xml_channel_list = []\n",
    "            stacked_array = np.stack(array_list, axis=2)\n",
    "            transposed_array = np.transpose(stacked_array, (2, 0, 1))\n",
    "            file_name = block_files[0]\n",
    "            file_name = file_name[:-10]\n",
    "            for count, value in enumerate(channels):\n",
    "                if value == 0:\n",
    "                    chn = Channel(\n",
    "                        id=f\"Channel:{round}:{count}\",\n",
    "                        acquisition_mode=\"BrightField\",\n",
    "                        samples_per_pixel = f\"{pixel}\"\n",
    "                    )\n",
    "                    xml_channel_list.append(chn)\n",
    "                else:\n",
    "                    chn = Channel(\n",
    "                        id=f\"Channel:{round}:{count}\",\n",
    "                        acquisition_mode=\"FluorescenceCorrelationSpectroscopy\",\n",
    "                        fluor=\"Natural\",\n",
    "                        excitation_wavelength= int(value),\n",
    "                        excitation_wavelength_unit=\"nm\"\n",
    "                    )\n",
    "                    xml_channel_list.append(chn)\n",
    "            ome = OME(\n",
    "                uuid=\"urn:uuid:\" + str(uuid.uuid4()),\n",
    "                creator=\"tifffile --v tifffile 2023.7.10\")\n",
    "            tfd = TiffData(\n",
    "                first_c=0,\n",
    "                first_t=0,\n",
    "                first_z=0,\n",
    "                ifd=0,\n",
    "                plane_count=1,\n",
    "                uuid=TiffData.UUID(\n",
    "                    file_name=f\"{file_name}.tiff\",\n",
    "                    value=\"urn:uuid:\" + str(uuid.uuid4())\n",
    "                ))\n",
    "            img = Image(\n",
    "                id=f\"Image:{round}\",\n",
    "                name=f\"{file_name}.tiff\",\n",
    "                pixels=Pixels(\n",
    "                    id=f\"Pixels:{round}\",\n",
    "                    channels=xml_channel_list,\n",
    "                    tiff_data_blocks=[tfd],\n",
    "                    type=f\"{dtype}\",\n",
    "                    dimension_order=\"XYCTZ\",\n",
    "                    significant_bits = f\"{bits}\",\n",
    "                    size_x=f\"{width}\",\n",
    "                    size_y=f\"{lenght}\",\n",
    "                    size_z=1,\n",
    "                    size_c= f\"{len(channels)}\",\n",
    "                    size_t=1)\n",
    "            )\n",
    "            ome.images.append(img)\n",
    "            ome = to_xml(ome, validate=True)\n",
    "            tifffile.imwrite(f\"{files_output}/{file_name}.ome.tiff\",\n",
    "                             transposed_array,\n",
    "                             dtype=transposed_array.dtype,\n",
    "                             shape=transposed_array.shape,\n",
    "                             metadata={'axes': 'CYX'},\n",
    "                             description= ome)\n",
    "            round += 1\n",
    "\n",
    "\n",
    "def associate_mask(conn, dts, path, channels):\n",
    "    dataset = conn.getObject(\"Dataset\", dts)\n",
    "    ID = []\n",
    "    for image in dataset.listChildren():\n",
    "        ID.append(image.getId())\n",
    "    mask_folder_path = path\n",
    "    os.chdir(mask_folder_path)\n",
    "    files = os.listdir(mask_folder_path)\n",
    "    for im in ID:\n",
    "        print(f\"Processing Image with ID:{im}\")\n",
    "        image = conn.getObject(\"Image\", im)\n",
    "        channel = 0\n",
    "        for i in files:\n",
    "            if channel <= channels:\n",
    "                img = imread(path)\n",
    "                # Apply thresholding to convert the grayscale img to binary\n",
    "                threshold = filters.threshold_otsu(img)\n",
    "                binary_image = img >= threshold\n",
    "                # Convert binary img to binary array\n",
    "                binary_array = (binary_image / 255).astype(np.int64)\n",
    "                mask = omero_rois.mask_from_binary_image(binary_array, rgba=(255, 0, 0, 150), z=0, c=channel, t=0,\n",
    "                                                         text=f\"Channel_{channel}\", raise_on_no_mask=False)\n",
    "                create_roi(image, [mask])\n",
    "                channel += 1\n",
    "                os.remove(i)\n",
    "            else:\n",
    "                files = files[channels:]\n",
    "                print(f\"Finish mask upload with ID:{im}\")\n",
    "                break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 1) Extract images and metadata\n",
    "\n",
    "The R script can be run in the Jupyter Notebook thanks to the package rpy2 \n",
    "(https://towardsdatascience.com/guide-to-r-and-python-in-a-single-jupyter-notebook-ff12532eb3ba)"
   ],
   "id": "94e97766680f4ec9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "path_to_R = input(\"Specify the path to R:\")\n",
    "os.environ['R_HOME'] = f\"{path_to_R}\"\n",
    "from rpy2.robjects.packages import IFC\n",
    "from rpy2.robjects.packages import jsonlite\n",
    "\n",
    "setwd(\"/working_directory_where_cif_files_are\")\n",
    "\n",
    "## get exemplary data from IFCdata - Change accordingly\n",
    "test_data = system.file(package = \"IFCdata\", \"extdata\", \"example.cif\")\n",
    "## test_data = \"path_to_your_data\"\n",
    "\n",
    "#EXTRACT OFFSETS\n",
    "## extracts offsets of the IFDs (Image Field Directories) within a XIF file. \n",
    "cif_offs <- getOffsets(fileName = test_data, fast = FALSE)\n",
    "\n",
    "#EXTRACT METADATA\n",
    "## get metadata: Retrieves rich information from RIF, CIF and DAF files.\n",
    "metadata <- getInfo(fileName = test_data, from = \"analysis\")\n",
    "metadata$illumination$Channel <- 1:nrow(metadata$illumination)\n",
    "## extract metadata and save it as json file\n",
    "wavelenght <- as.list(metadata$illumination$wavelength)\n",
    "metadata_flat <- list(number_objects = metadata$objcount,\n",
    "                      date = metadata$date,\n",
    "                      instrument = metadata$instrument,\n",
    "                      brightfield = metadata$brightfield,\n",
    "                      illumination = metadata$illumination,\n",
    "                      images = metadata$Images,\n",
    "                      mask = metadata$masks,\n",
    "                      wavelenght = wavelenght)\n",
    "json_data <- toJSON(metadata_flat, pretty = TRUE)\n",
    "write(json_data, file = \"metadata.json\")\n",
    "\n",
    "#Extract images\n",
    "## 1) count the number of objects\n",
    "nobj <- as.integer(metadata$objcount)\n",
    "\n",
    "## 2) OPTIONAL: subset objects from the .cif file\n",
    "sel <- sample(0:(nobj-1), min(5, nobj))\n",
    "sub_offs <- subsetOffsets(cif_offs, objects = sel, image_type = \"img\")\n",
    "\n",
    "# 3) extracts IFDs (Image File Directory) in RIF or CIF files.\n",
    "## IFDs contain information about images or masks of objects stored within XIF files.\n",
    "## the first IFD is special in that it does not contain image of mask information but general information about the file.\n",
    "IFDs <- getIFD(fileName = test_data, offsets = sub_offs)\n",
    "\n",
    "## 4) Extract Images and Masks\n",
    "\n",
    "objectExtract(ifd = IFDs, info = metadata, mode = \"gray\",\n",
    "              export = \"file\",\n",
    "              write_to = \"%d/%s/%s_%o_%c.tiff\",\n",
    "              overwrite = TRUE,\n",
    "              selection = \"all\",\n",
    "              force_range = TRUE)\n",
    "\n",
    "\n",
    "ExtractMasks_toFile(raw, objects = sel, offsets = cif_offs, force_range = TRUE,\n",
    "                    write_to = \"%d/%s/%s_%o_%c.tiff\",\n",
    "                    base64_id = TRUE, add_noise = FALSE)"
   ],
   "id": "a71b1983189ba4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2) Create the multichannel images/mask and import them into OMERO using ezomero",
   "id": "c7c8a9046d8e754d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Connect to OMERO",
   "id": "9ddf0d96a7567f3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "OMEROUSER = input(f\"Enter username: \\t\")\n",
    "OMEROPASS = getpass.getpass(prompt = f\"Enter password: \\t\")\n",
    "\n",
    "OMEROHOST = \"localhost\"\n",
    "OMEROPORT = \"4064\"\n",
    "\n",
    "# Connection Check:\n",
    "conn=ezomero.connect(OMEROUSER, OMEROPASS, \"\", host=OMEROHOST, port=OMEROPORT, secure=True)\n",
    "\n",
    "## Information about the connection and its status\n",
    "print(conn.isConnected())\n",
    "user = conn.getUser()\n",
    "print(\"Current user:\")\n",
    "print(\"   ID:\", user.getId())\n",
    "print(\"   Username:\", user.getName())\n",
    "print(\"   Full Name:\", user.getFullName())"
   ],
   "id": "5490a52665b93035"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create the multichannel images, import them into OMERO and associate masks",
   "id": "461b08e13fcf1fe5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "files_path = input(f\"Images file path: \\t\")\n",
    "path = input(f\"Mask file path: \\t\")\n",
    "channels = input(f\"Number of channels: \\t\")\n",
    "metadata_path = input(f\"Metadata path: \\t\")\n",
    "files_output = input(f\"Name of the folder where to export multichannel images: \\t\")\n",
    "\n",
    "\n",
    "## Create the multichannel Images\n",
    "multi_channel_conversion(files_path, metadata_path, files_output)\n",
    "## Create a new dataset\n",
    "dts = ezomero.post_dataset(conn, \"Processed\", project_id=1)\n",
    "## push the image with REMBI annotation for analyzed data\n",
    "ezomero.ezimport(conn, files_output, dataset= dts)\n",
    "## Associate masks\n",
    "associate_mask(conn, dts, path, channels)"
   ],
   "id": "d0e660a7758f072c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
